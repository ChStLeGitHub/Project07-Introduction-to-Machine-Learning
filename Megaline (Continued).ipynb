{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "[Introduction](#1)\n",
    "\n",
    "[Section 1: Open and look through the data file](#2)\n",
    "\n",
    "[Section 2: Split data into training set, validation set, and test set](#3)\n",
    "\n",
    "[Section 3: Investigate different models by changing hyperparameters](#4)\n",
    "- [Decision Tree Models](#4.1)\n",
    "- [Random Forest Models](#4.2)\n",
    "- [Logistic Regression Models](#4.3)\n",
    "\n",
    "[Section 4: Check model quality using the test set](#5)\n",
    "\n",
    "[Section 5: Sanity check the models](#6)\n",
    "\n",
    "[Conclusion](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id=1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am an analyst for **Megaline**, a mobile carrier that is concerned about the fact that many of their subscribers continue to use legacy plans. \n",
    "\n",
    "**Megaline** wants me to develop a model that can analyze subscribers' behavior and recommend one of **Megaline**'s newer plans: ***Smart*** or ***Ultra***.\n",
    "\n",
    "To help me develop the model, I have access to a dataset of the behavior of the subscribers who have already switched to one of the new plans. \n",
    "\n",
    "The model needs to be able to pick the correct plan with at least 75% accuracy, otherwise it would risk having **Megaline** lose too many of their legacy subscribers due to them receiving an inaccurate recommendation that would turn them off from trusting **Megaline** with giving them a plan that is a good fit.\n",
    "\n",
    "I acquire the model by following the steps below:\n",
    "\n",
    "1) Opening the data file and looking through it. \n",
    "\n",
    "2) Splitting the source data into a training set, a validation set, and a test set.\n",
    "\n",
    "3) Investigating the quality of different models by changing the hyperparameters.\n",
    "\n",
    "4) Checking the quality of the two best models I found using the test set.\n",
    "\n",
    "5) Doing a sanity check of the two best models I found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Open and look through the data file <a id=2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset of the behavior of the subscribers who have already switched to a newer plan has the following column names:\n",
    "\n",
    "**сalls** — Number of calls made in a month\n",
    "\n",
    "**minutes** — Total call duration, in minutes, in a month\n",
    "\n",
    "**messages** — Number of text messages sent in a month\n",
    "\n",
    "**mb_used** — Total internet traffic used, in MB, in a month\n",
    "\n",
    "**is_ultra** — The subscriber's plan for the month (\"1\" means ***Ultra***, \"0\" means ***Smart***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_behavior = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, it is a good idea to display a random sample of rows of the dataframe being used to get a concrete idea of what the dataframe \"looks like\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>64.0</td>\n",
       "      <td>431.95</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28294.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>79.0</td>\n",
       "      <td>505.50</td>\n",
       "      <td>105.0</td>\n",
       "      <td>12406.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>18.0</td>\n",
       "      <td>147.93</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1904.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.0</td>\n",
       "      <td>77.09</td>\n",
       "      <td>31.0</td>\n",
       "      <td>643.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>66.0</td>\n",
       "      <td>460.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15402.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>40.0</td>\n",
       "      <td>300.10</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>72.0</td>\n",
       "      <td>495.11</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15887.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>69.0</td>\n",
       "      <td>469.46</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15362.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>42.0</td>\n",
       "      <td>328.73</td>\n",
       "      <td>61.0</td>\n",
       "      <td>23573.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>117.0</td>\n",
       "      <td>779.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11308.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "231    64.0   431.95      24.0  28294.62         0\n",
       "3165   79.0   505.50     105.0  12406.00         0\n",
       "651    18.0   147.93      18.0   1904.01         1\n",
       "31     10.0    77.09      31.0    643.15         0\n",
       "3113   66.0   460.33       0.0  15402.88         0\n",
       "2892   40.0   300.10      35.0      0.00         1\n",
       "1355   72.0   495.11      34.0  15887.37         0\n",
       "1297   69.0   469.46      55.0  15362.48         0\n",
       "2328   42.0   328.73      61.0  23573.96         1\n",
       "584   117.0   779.50       0.0  11308.65         1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(users_behavior.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The info() function is a way to display general information about a dataframe, especially the number of non-null values and the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "users_behavior.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is great to see that all of the column names are in snake_case, and that there are no null values. \n",
    "\n",
    "The Dtypes are all acceptable, however I think that the **calls** and **messages** column values should be changed to Dtype int64 because number of calls and number of messages are always going to be whole numbers, not decimals.\n",
    "\n",
    "Furthermore, this is a (binary) classification task because the target, recommending the ***Smart*** plan or the ***Ultra*** plan, is categorical, not numerical. \n",
    "\n",
    "Hence, I will change the **is_ultra** Dtype from int64 to string, the 1s to \"Ultra\", the 0s to \"Smart\", and the column name to **smart_or_ultra**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   calls           3214 non-null   int64  \n",
      " 1   minutes         3214 non-null   float64\n",
      " 2   messages        3214 non-null   int64  \n",
      " 3   mb_used         3214 non-null   float64\n",
      " 4   smart_or_ultra  3214 non-null   object \n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "users_behavior['calls'] = users_behavior['calls'].astype(int)\n",
    "users_behavior['messages'] = users_behavior['messages'].astype(int)\n",
    "\n",
    "users_behavior['is_ultra'] = users_behavior['is_ultra'].astype(str)\n",
    "users_behavior['is_ultra'] = users_behavior['is_ultra'].replace('1', 'Ultra')\n",
    "users_behavior['is_ultra'] = users_behavior['is_ultra'].replace('0', 'Smart')\n",
    "users_behavior = users_behavior.rename(columns = {'is_ultra': 'smart_or_ultra'})\n",
    "\n",
    "users_behavior.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before working with a dataframe, it is always a good idea to check to see if there are any rows that are exact duplicates. If so, then the duplicates should be dropped from the dataframe because they are most likely there by mistake. (After all, it is <u>highly</u> unlikely that any two distinct Megaline subscribers would have the exact same **calls**, **minutes**, **messages**, **mb_used**, and **smart_or_ultra** values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>smart_or_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [calls, minutes, messages, mb_used, smart_or_ultra]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(users_behavior[users_behavior.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, the code below shows that there are no exact duplicates, hence I won't drop any rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Split data into training set, validation set, and test set <a id=3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <u>target</u> of the model is the **smart_or_ultra** value. The **calls**, **minutes**, **messages**, and **mb_used** values of the source data will all help with making predictions. Since a test set doesn't exist, I need to make one using the source data, as well as a training set and a validation set. A commonly used ratio when splitting source data into three parts is 60% training, 20% validation, and 20% test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the three parts, I will first construct the test set, but I am curious to check something first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>smart_or_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3206</th>\n",
       "      <td>76</td>\n",
       "      <td>586.51</td>\n",
       "      <td>54</td>\n",
       "      <td>14345.74</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>17</td>\n",
       "      <td>92.39</td>\n",
       "      <td>2</td>\n",
       "      <td>4299.25</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>25</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>97</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>64</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>Smart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2229 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used smart_or_ultra\n",
       "0        40   311.90        83  19915.42          Smart\n",
       "1        85   516.75        56  22696.96          Smart\n",
       "2        77   467.66        86  21060.45          Smart\n",
       "4        66   418.74         1  14502.75          Smart\n",
       "5        58   344.56        21  15823.37          Smart\n",
       "...     ...      ...       ...       ...            ...\n",
       "3206     76   586.51        54  14345.74          Smart\n",
       "3207     17    92.39         2   4299.25          Smart\n",
       "3210     25   190.36         0   3275.61          Smart\n",
       "3211     97   634.44        70  13974.06          Smart\n",
       "3212     64   462.32        90  31239.78          Smart\n",
       "\n",
       "[2229 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(users_behavior[users_behavior['smart_or_ultra'] == 'Smart'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 3214 subscribers in the source data, 2229 of them have the ***Smart*** plan, i.e. approximately 69%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>smart_or_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82</td>\n",
       "      <td>560.51</td>\n",
       "      <td>20</td>\n",
       "      <td>9619.53</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108</td>\n",
       "      <td>587.90</td>\n",
       "      <td>0</td>\n",
       "      <td>14406.50</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>56</td>\n",
       "      <td>419.42</td>\n",
       "      <td>59</td>\n",
       "      <td>5177.62</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>53</td>\n",
       "      <td>390.39</td>\n",
       "      <td>85</td>\n",
       "      <td>30550.30</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>164</td>\n",
       "      <td>1016.98</td>\n",
       "      <td>71</td>\n",
       "      <td>17787.52</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>122</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>80</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>Ultra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used smart_or_ultra\n",
       "3       106   745.53        81   8437.39          Ultra\n",
       "6        57   431.64        20   3738.90          Ultra\n",
       "8         7    43.39         3   2538.67          Ultra\n",
       "10       82   560.51        20   9619.53          Ultra\n",
       "14      108   587.90         0  14406.50          Ultra\n",
       "...     ...      ...       ...       ...            ...\n",
       "3201     56   419.42        59   5177.62          Ultra\n",
       "3203     53   390.39        85  30550.30          Ultra\n",
       "3208    164  1016.98        71  17787.52          Ultra\n",
       "3209    122   910.98        20  35124.90          Ultra\n",
       "3213     80   566.09         6  29480.52          Ultra\n",
       "\n",
       "[985 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(users_behavior[users_behavior['smart_or_ultra'] == 'Ultra'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, the remaining 985 subscribers, i.e. approximately 31%, in the source data have the ***Ultra*** plan.\n",
    "\n",
    "It would be nice if all three parts of the source data had approximately the same proportion of **smart_or_ultra** values, so I will use the **stratify** parameter of the **train_test_split** function. I imagine that doing this would help the model be more precise!\n",
    "\n",
    "The next line of code constructs the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, users_behavior_test = train_test_split(users_behavior, test_size = 0.2, \n",
    "                                          stratify = users_behavior['smart_or_ultra'], random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to make sure that none of the rows in the test set end up appearing in the training and/or validation sets.\n",
    "\n",
    "The new dataframe in the next line of code is the complement of the **users_behavior_test** dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_behavior_not_test = users_behavior.drop(users_behavior_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will split the **users_behavior_not_test** dataframe into the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_behavior_train, users_behavior_valid = train_test_split(users_behavior_not_test, test_size = 0.25, \n",
    "                                                              stratify = users_behavior_not_test['smart_or_ultra'], \n",
    "                                                              random_state = 6020) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I set **test_size** equal to 0.25. The reason why this is correct is as follows:\n",
    "\n",
    "- The source data has 3214 rows, and the test set has 643, which is about 20% of 3214. \n",
    "- I want the validation set to also have 643 rows so that I get my desired ratio. \n",
    "- The validation set is coming from the **users_behavior_not_test** dataframe which has 2571 rows.\n",
    "- 643 is approximately 25% of 2571."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Investigate different models by changing hyperparameters <a id=4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I can investigate different models by changing hyperparameters, I must declare the variables for the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = users_behavior_test.drop(['smart_or_ultra'], axis = 1)\n",
    "target_test = users_behavior_test['smart_or_ultra']\n",
    "\n",
    "features_train = users_behavior_train.drop(['smart_or_ultra'], axis = 1)\n",
    "target_train = users_behavior_train['smart_or_ultra']\n",
    "\n",
    "features_valid = users_behavior_valid.drop(['smart_or_ultra'], axis = 1)\n",
    "target_valid = users_behavior_valid['smart_or_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DECISION TREE MODELS** <a id=4.1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model I will investigate is a decision tree. Before I change any hyperparameters, I am curious to see how accurate the default decision tree is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Percentage: 71.07309486780716\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model = DecisionTreeClassifier(random_state = 0)\n",
    "    \n",
    "decision_tree_model.fit(features_train, target_train)\n",
    "\n",
    "decision_tree_predictions_valid = decision_tree_model.predict(features_valid)\n",
    "\n",
    "print('Accuracy Percentage:', accuracy_score(target_valid, decision_tree_predictions_valid)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not good enough! I am looking for at least 75% accuracy. \n",
    "\n",
    "Maybe the decision tree will be more accurate if I specify the value of the **max_depth** hyperparameter? This is the most important hyperparameter of a decision tree because it helps control for overfitting and underfitting. If the **max_depth** value is too large, then overfitting will occur, whereas if it is too small, underfitting will occur. The code below loops this hyperparameter's value from 1 to 15, and prints the values whose accuracies are at least 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 2 ; Accuracy Percentage = 76.98289269051321\n",
      "max_depth = 3 ; Accuracy Percentage = 78.53810264385692\n",
      "max_depth = 4 ; Accuracy Percentage = 78.53810264385692\n",
      "max_depth = 5 ; Accuracy Percentage = 78.69362363919129\n",
      "max_depth = 6 ; Accuracy Percentage = 78.84914463452566\n",
      "max_depth = 7 ; Accuracy Percentage = 78.53810264385692\n",
      "max_depth = 8 ; Accuracy Percentage = 78.0715396578538\n",
      "max_depth = 9 ; Accuracy Percentage = 77.60497667185071\n",
      "max_depth = 10 ; Accuracy Percentage = 78.22706065318819\n",
      "max_depth = 11 ; Accuracy Percentage = 78.38258164852256\n",
      "max_depth = 12 ; Accuracy Percentage = 75.42768273716952\n",
      "max_depth = 13 ; Accuracy Percentage = 76.36080870917574\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 16):\n",
    "    decision_tree_model = DecisionTreeClassifier(random_state = 1, max_depth = depth)\n",
    "    decision_tree_model.fit(features_train, target_train)\n",
    "    decision_tree_predictions_valid = decision_tree_model.predict(features_valid)\n",
    "    if accuracy_score(target_valid, decision_tree_predictions_valid)*100 >= 75:\n",
    "        print('max_depth =', depth, '; ', end = '')\n",
    "        print('Accuracy Percentage =', accuracy_score(target_valid, decision_tree_predictions_valid)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! The most accurate decision tree is the one with a **max_depth** value of 6, which has an accuracy of about 78.8%. \n",
    "\n",
    "While the decision tree with a **max_depth** value of 6 is accurate enough for this project, I wonder if there exist an even more accurate model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOM FOREST MODELS** <a id=4.2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees sacrifice accuracy for speed, whereas random forests sacrifice speed for accuracy. Since I desire a model that is even more accurate than 78.8%, let's see how accurate the default random forest will be, followed by seeing how accuracy changes as I change the **n_estimators** hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Percentage: 80.40435458786936\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state = 2)\n",
    "    \n",
    "random_forest_model.fit(features_train, target_train)\n",
    "\n",
    "print('Accuracy Percentage:', random_forest_model.score(features_valid, target_valid)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 78.8% to 80.4% is a small, but appreciated improvement. \n",
    "\n",
    "Now I will loop the **n_estimators** hyperparameter's value from 1 to 100. I realize that this is ***a lot*** of values, and it would take a long time to print all 100 results, so I write the loop in such a way that it only prints the **n_estimator** values that have at least 81% accuracy (which is 80.4% rounded up to the nearest integer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 22 ; Accuracy Percentage = 81.02643856920683\n",
      "n_estimators = 38 ; Accuracy Percentage = 81.33748055987559\n",
      "n_estimators = 84 ; Accuracy Percentage = 81.02643856920683\n",
      "n_estimators = 86 ; Accuracy Percentage = 81.02643856920683\n",
      "n_estimators = 88 ; Accuracy Percentage = 81.18195956454122\n",
      "n_estimators = 89 ; Accuracy Percentage = 81.18195956454122\n",
      "n_estimators = 90 ; Accuracy Percentage = 81.02643856920683\n",
      "n_estimators = 94 ; Accuracy Percentage = 81.02643856920683\n",
      "n_estimators = 95 ; Accuracy Percentage = 81.18195956454122\n"
     ]
    }
   ],
   "source": [
    "for n_est in range(1, 101):\n",
    "    random_forest_model = RandomForestClassifier(random_state = 3, n_estimators = n_est)\n",
    "    random_forest_model.fit(features_train, target_train)\n",
    "    random_forest_model_score = random_forest_model.score(features_valid, target_valid)\n",
    "    if random_forest_model_score*100 > 81:\n",
    "        print('n_estimators =', n_est, '; ', end = '')\n",
    "        print('Accuracy Percentage =', random_forest_model_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oddly enough, the second smallest **n_estimators** value in the above list, 38, is the one that is most accurate, about 81.3%. \n",
    "\n",
    "I find it interesting how the **n_estimators** values of 22, 84, 86, 90, and 94 all have the same accuracy, as do the **n_estimators** values of 88, 89, and 95. \n",
    "\n",
    "22 is a ***much*** smaller number than 84, 86, 90, and 94, so I find it especially odd that 22 yielded the same accuracy as the other four numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION MODELS** <a id=4.3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I wonder how accurate a logistic regression model is for this project's source data. Though logisitic regression models tend to be less accurate than random forest models, logisitic regression models tend to be much faster than random forests, as well as tend to be more accurate than decision tree models. \n",
    "\n",
    "The first value for the **solver** hyperparameter I learned about is \"liblinear\", so I will test that one first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the logistic regression model on the training set (%): 70.33195020746888\n",
      "Accuracy of the logistic regression model on the validation set (%): 70.45101088646967\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state = 4, solver = \"liblinear\")\n",
    "\n",
    "logistic_model.fit(features_train, target_train)\n",
    "\n",
    "logistic_model_score_train = logistic_model.score(features_train, target_train)\n",
    "logistic_model_score_valid = logistic_model.score(features_valid, target_valid)\n",
    "\n",
    "print(\"Accuracy of the logistic regression model on the training set (%):\", logistic_model_score_train*100)\n",
    "print(\"Accuracy of the logistic regression model on the validation set (%):\", logistic_model_score_valid*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is actually (slightly) worse than that of the initial decision tree model. \n",
    "\n",
    "Generally speaking, setting **solver** equal to \"liblinear\" is a good choice if the dataset is small, but I am not sure if this project's dataset should be classifed as small or not, so the next line of code loops through all possible **solver** values to see if changing this hyperparameter makes any significant difference to the accuracy of this logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver = liblinear\n",
      "Training Set Accuracy (%) = 70.33195020746888\n",
      "Validation Set Accuracy (%) = 70.45101088646967\n",
      "\n",
      "solver = lbfgs\n",
      "Training Set Accuracy (%) = 74.84439834024896\n",
      "Validation Set Accuracy (%) = 74.65007776049767\n",
      "\n",
      "solver = newton-cg\n",
      "Training Set Accuracy (%) = 74.84439834024896\n",
      "Validation Set Accuracy (%) = 74.65007776049767\n",
      "\n",
      "solver = sag\n",
      "Training Set Accuracy (%) = 69.34647302904564\n",
      "Validation Set Accuracy (%) = 69.36236391912908\n",
      "\n",
      "solver = saga\n",
      "Training Set Accuracy (%) = 69.34647302904564\n",
      "Validation Set Accuracy (%) = 69.36236391912908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "for method in [\"liblinear\", \"lbfgs\", \"newton-cg\", \"sag\", \"saga\"]:\n",
    "    logistic_model = LogisticRegression(random_state = 5, solver = method)\n",
    "    logistic_model.fit(features_train, target_train)\n",
    "    logistic_model_score_train = logistic_model.score(features_train, target_train)\n",
    "    logistic_model_score_valid = logistic_model.score(features_valid, target_valid)\n",
    "    print('solver =', method)\n",
    "    print('Training Set Accuracy (%) =', logistic_model_score_train*100)\n",
    "    print('Validation Set Accuracy (%) =', logistic_model_score_valid*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curiously, none of the five **solver** values gave me a model that is at least 75% accurate! The parameter values \"lbfgs\" and \"newton-cg\", which for one reason or another have the same accuracy, are both ***very*** close (about 74.8%), but very close is not good enough for this project. Furthermore, these two parameter values are the only ones who accuracy is better than that of the default decision tree, which I find counterintuitive.\n",
    "\n",
    "I could keep fiddling with the multiple different parameters of the logistic regression model, but I see no good reason to do so since I found a decision tree model and a random forest model that are more than 75% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Check model quality using the test set <a id=5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I must now choose between the decision tree model and the random forest model. I think the random forest is the better choice because it is more accurate without being overly computationally expensive. Let's now evaluate it using the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Percentage = 82.11508553654744\n"
     ]
    }
   ],
   "source": [
    "best_random_forest_model = RandomForestClassifier(random_state = 7, n_estimators = 38)\n",
    "\n",
    "best_random_forest_model.fit(features_train, target_train)\n",
    "\n",
    "best_random_forest_model_score = best_random_forest_model.score(features_test, target_test)\n",
    "\n",
    "print('Accuracy Percentage =', best_random_forest_model_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! As expected, this model is more than 75% accurate (just like what happened with the validation set)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Sanity check the models <a id=6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I observed earlier that about 69% of the subscribers in the source data have the ***Smart*** plan. Hence, an appropriate dummy model to use to sanity check the two best models from **Section 4: Check model quality using the test set** is one that assumes 100% of subscribers have the ***Smart*** plan. Such a model would be correct about 69% of the time, which is not only less than 75% accurate (the minimum acceptable accuracy rate), it is clearly far less accurate than the at least 80% accuracy that the decision tree and random forest are capable of getting. I can safely declare this sanity check successful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a id=7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to splitting the source data into three sets (training, validation, and test) and using these sets to investigate three different machine learning models (decision tree, random forest, and logistic regression), I successfully constructed two models that can predict with more than 75% accuracy which new(er) **Megaline** plan, ***Smart*** or ***Ultra***, is a better recommendation for subscribers who are currently using a legacy plan. \n",
    "\n",
    "For each of the three different models, I tried out multiple different values for a major hyperparameter in the hopes of finding an accurate enough model of each type. Unfortunately, I was unable to construct a logistic regression model, but that honestly is not an issue because my testing throughout this project demonstrates that the decision tree and random forest models are by all means suitable to help **Megaline** achieve its goal.The optimal **max_depth** value for the decision tree model is 6, and the optimal **n_estimators** value for the random forest is 38. \n",
    "\n",
    "I recommend **Megaline** stakeholders to choose the random forest model because though it takes more time to run than the decision tree model, it appears to be about 1 to 3 percentage points more accurate. Though this might not sound like much, in the long run, the random forest model would likely result in a significantly larger number of subscribers switching from a legacy plan to a newer plan (thanks to receiving a recommendation) than would the decision tree model to the point that the random forest model yields significantly more revenue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
